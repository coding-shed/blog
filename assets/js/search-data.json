{
  
    
        "post0": {
            "title": "Simulating trajectories of 3 celestial bodies",
            "content": "Simulating trajectories of 3 celestial bodies . Today we are going to simulate paths of 3 moving celestial bodies. To do so, we don&#39;t need maths or astro-physics degree. In today&#39;s day and age, world class computational tools are at out fingertips. We&#39;re going to leverage them to solve what hundred of years ago was deemed unsolvable. . Universal Law of Gravity . The following two equations, along with godlike ingenuity, allowed Issac Newton to determine orbital position of celestial bodies at any given point in time. First is the Universal Law of Gravity, which states that gravitational force between two bodies is proportional to their masses and inversely proportional to the square of their distance. . $${F} = {G} times frac{m_1 m_2}{{r}^2}$$ . Second equation is Newtown&#39;s Second Law of Motion. It tells us that with constant mass, net force applied to a body yields proportional acceleration. . $${F} = {m_1} times {a}$$ . Combining those two facts i.e. equating those two definitions of force, gives a way to infer about object acceleration. But since we want to follow objects path in 3 dimensions, we have to turn above equation into vector form. Force and acceleration both have direction. In order to reflect that, we can add unit vector (with a hat) that points from body m1 towards body m2 . $$ vec{a} = {G} times frac{m_2}{r^2} hat{r}$$ . And since unit vector is defined as vector divided by its norm, we can re-write the above into: . $$ vec{a} = {G} times frac{m_2}{r^3} vec{r}_{12}$$ . Subscript &quot;12&quot; means &quot;from 1 towards 2&quot; to describe vector&#39;s direction. . Working out the position . Now that we have acceleration, we can also derive body velocities and position. Acceleration is a derivative of velocity, and velocity is a derviative of position with respect to time. So, from acceleration we need to take two steps down: to velocity, and then to position. This can be expressed with two first order differential equations: . $$ frac{ partial vec{v}_{i}}{ partial t} = {G} times frac{m_j}{r^3_{ij}} vec{r}_{ij}$$ $$ frac{ partial vec{r}_{i}}{ partial t} = vec{v}_{i} $$ . Introducing third celestial body . Above equations are fine for systems with 2 bodies, not three. We still need to factor in the effect the third body has on both first and second body. With each body in question, the net exerted force will be the sum of forces from two remaining bodies. For example, acceleration of body 1 can be expressed as: . $$ frac{ partial vec{v}_{1}}{ partial t} = frac{m_2}{r^3_{12}} vec{r}_{12} + frac{m_3}{r^3_{13}} vec{r}_{13} $$Coding the equations . Now we are fully equiped to code a set of 3 acceleration equations. First, let&#39;s import all required packages. . import scipy as sci import matplotlib.pyplot as plt from mpl_toolkits.mplot3d import Axes3D from matplotlib import animation import numpy as np import pandas as pd import scipy.integrate . Function equations_system will accept state vector w, which comprises position coordinates of three bodies followed by velocity vectors, 18 floating point values in total: (3 bodies x 3 positions) + (3 bodies x 3 velocities) = 18. You can see that I skipped G constant in each acceleration equation. That&#39;s because we want all parameters provided to integrator to have similator magnitudes close to unity. This will make numerical methods work much better. One other solution would be to scale all of the parameters by some reference quantities to keep relative differences between them. But here, we are not mimicking any real celestial system. It&#39;s a toy example with completely arbitrary, random values. . def equations_system(w,t,m1,m2,m3): r1, r2, r3 = w[:3], w[3:6], w[6:9] v1, v2, v3 = w[9:12], w[12:15], w[15:18] r12=np.linalg.norm(r2-r1) r13=np.linalg.norm(r3-r1) r23=np.linalg.norm(r3-r2) a1=m2/r12**3*(r2-r1)+m3/r13**3*(r3-r1) a2=m1/r12**3*(r1-r2)+m3/r23**3*(r3-r2) a3=m1/r13**3*(r1-r3)+m2/r23**3*(r2-r3) r_derivs=np.concatenate((v1,v2,v3)) v_derivs=np.concatenate((a1,a2,a3)) derivs=np.concatenate((r_derivs,v_derivs)) return derivs . Next, we calculate magnitudes of distance vectors, remembering that vector AB from A to B is obtained by substracting initial point from terminal point: B - A. That&#39;s why r12 is defined as magnitude of r2-r1. Finally, we substitute state vector with updated values - what previosly was positions, now becomes velocity, and what was velocity is substituted with acceleration. . System of equation can now be fed into our main function that does all the work i.e. numerical integration along every time step provided. This is done by odeint function which requires: initial parameters (starting points), and amount of timesteps to perform calculations. Snapshot of positions at each timestep will create our trajectories. . def solve_equations(equations_system, initial_parameters, time_span, constants): solution=sci.integrate.odeint(equations_system, initial_parameters, time_span, args=constants) return solution . Now we can initialise starting parameters i.e. individual masses of objects, positions and velocities along with timespan. Last two lines create dataframe from solution set and generate gif file visualizing the bodies trajectories. For clarity the visualization functions are put at the end of the blogpost. . m1=1.1 m2=0.907 m3=1.2 r1=np.random.uniform(low=-2, high=2, size=(3,)) r2=np.random.uniform(low=-2, high=2, size=(3,)) r3=np.random.uniform(low=-2, high=2, size=(3,)) v1=np.random.uniform(low=-0.5, high=0.5, size=(3,)) v2=np.random.uniform(low=-0.5, high=0.5, size=(3,)) v3=np.random.uniform(low=-0.5, high=0.5, size=(3,)) initial_parameters = np.array([r1,r2,r3,v1,v2,v3]).flatten() time_span=np.linspace(0,30,700) constants = (m1,m2,m3) solution = solve_equations(equations_system, initial_parameters, time_span, constants) df = build_dataframe(solution) create_animation(f&#39;animation_{num}.gif&#39;, df) . Sample trajectories . Below are sample trajectories with random initial parameters that I&#39;ve found interesting. Feel free to play around with parameters - or even reproduce real-world 3 body systems! . . Final remark . There is a strong simplifying assumption made in the simulation. Not only we are assuming that gravitational center of mass is a infinitisemaly small point, but also that the entire object is this small point. This means we are assuming all bodies have volume equal 0. Under such assumption, the bodies will never collide. And from the animatrions above it is clear they should multiple times. . . . . Code appendix . . def build_dataframe(solution): data = np.array([solution[:,:3], solution[:,3:6], solution[:,6:9]]) df = pd.DataFrame({}) for body in range(3): for dimension in range(3): df[f&#39;body{body}_dim{dimension}&#39;] = data[body][:,dimension] return df def update_graph(num, data, graph1, graph2, graph3, dots1, dots2, dots3): graph1.set_data(df.body0_dim0[:num+1], df.body0_dim1[:num+1]) graph1.set_3d_properties(df.body0_dim2[:num+1]) graph2.set_data(df.body1_dim0[:num+1], df.body1_dim1[:num+1]) graph2.set_3d_properties(df.body1_dim2[:num+1]) graph3.set_data(df.body2_dim0[:num+1], df.body2_dim1[:num+1]) graph3.set_3d_properties(df.body2_dim2[:num+1]) dots1.set_data(df.body0_dim0[num], df.body0_dim1[num]) dots1.set_3d_properties(df.body0_dim2[num]) dots2.set_data(df.body1_dim0[num], df.body1_dim1[num]) dots2.set_3d_properties(df.body1_dim2[num]) dots3.set_data(df.body2_dim0[num], df.body2_dim1[num]) dots3.set_3d_properties(df.body2_dim2[num]) return graph1, graph2, graph3, dots1, dots2, dots3, def define_ax(ax): ax.set_xlim3d(-2, 2) ax.set_ylim3d(-3, 1) ax.set_zlim3d(-3, 1) x, y, z = 10*(np.random.rand(3,1000)-0.5) ax.scatter(x, y, z, s=0.2, c=&#39;w&#39;) ax.set_facecolor(&#39;black&#39;) ax.grid(False) ax.w_xaxis.pane.fill = False ax.w_yaxis.pane.fill = False ax.w_zaxis.pane.fill = False def create_animation(file_pathname, df): fig=plt.figure(figsize=(10,10)) fig.set_facecolor(&#39;black&#39;) ax = Axes3D(fig) define_ax(ax) graph1, = ax.plot(df.body0_dim0, df.body0_dim1, df.body0_dim2, alpha=0.35, color=&quot;#FFFFF0&quot;) graph2, = ax.plot(df.body1_dim0, df.body1_dim1, df.body1_dim2, alpha=0.35, color=&quot;#FFFFCB&quot;) graph3, = ax.plot(df.body2_dim0, df.body2_dim1, df.body2_dim2, alpha=0.35, color=&quot;#F0FFFF&quot;) dots1, = ax.plot(df.body0_dim0[0], df.body0_dim1[0], df.body0_dim2[0], marker=&quot;o&quot;,linestyle=&#39;&#39;, markersize=12, color=&quot;#FFFFF0&quot;) dots2, = ax.plot(df.body1_dim0[0], df.body1_dim1[0], df.body1_dim2[0], marker=&quot;o&quot;,linestyle=&#39;&#39;, markersize=12, color=&quot;#FFFFCB&quot;) dots3, = ax.plot(df.body2_dim0[0], df.body2_dim1[0], df.body2_dim2[0], marker=&quot;o&quot;,linestyle=&#39;&#39;, markersize=12, color=&quot;#F0FFFF&quot;) ani = animation.FuncAnimation(fig, update_graph, 700, fargs=(df, graph1, graph2, graph3, dots1, dots2, dots3), interval=500, blit=True) ani.save(file_pathname, writer=&#39;imagemagick&#39;, fps=24) #plt.show() .",
            "url": "https://coding-shed.com/physics/scipy/python/2021/07/15/Three-Bodies-Simulation.html",
            "relUrl": "/physics/scipy/python/2021/07/15/Three-Bodies-Simulation.html",
            "date": " • Jul 15, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Microsoft Word Example Post",
            "content": "When writing a blog post with Microsoft Word – the filename becomes the title. In this case the file name is “2020-01-01-Microsoft-Word-Example-Post.docx”. . There is minimal support for Word documents in fastpages compared to Jupyter notebooks. Some known limitations: . alt text in Word documents are not yet supported by fastpages, and will break links to images. . | You can only specify front matter for Word documents globally. See the README for more details. . | . For greater control over the content produced from Word documents, you will need to convert Word to markdown files manually. You can follow the steps in this blog post, which walk you through how to use pandoc to do the conversion. Note: If you wish to customize your Word generated blog post in markdown, make sure you delete your Word document from the _word directory so your markdown file doesn’t get overwritten! . If your primary method of writing blog posts is Word documents, and you plan on always manually editing Word generated markdown files, you are probably better off using fast_template instead of fastpages. . The material below is a reproduction of this blog post, and serves as an illustrative example. . Maintaining a healthy open source project can entail a huge amount of toil. Popular projects often have orders of magnitude more users and episodic contributors opening issues and PRs than core maintainers capable of handling these issues. . Consider this graphic prepared by the NumFOCUS foundation showing the number of maintainers for three widely used scientific computing projects: . . We can see that across these three projects, there is a very low ratio maintainers to users. Fixing this problem is not an easy task and likely requires innovative solutions to address the economics as well as tools. . Due to its recent momentum and popularity, Kubeflow suffers from a similar fate as illustrated by the growth of new issues opened: . . Source: “TensorFlow World 2019, Automating Your Developer Workflow With ML” . Coincidentally, while building out end to end machine learning examples for Kubeflow, we built two examples using publicly available GitHub data: GitHub Issue Summarization and Code Search. While these tutorials were useful for demonstrating components of Kubeflow, we realized that we could take this a step further and build concrete data products that reduce toil for maintainers. . This is why we started the project kubeflow/code-intelligence, with the goals of increasing project velocity and health using data driven tools. Below are two projects we are currently experimenting with : . Issue Label Bot: This is a bot that automatically labels GitHub issues using Machine Learning. This bot is a GitHub App that was originally built for Kubeflow but is now also used by several large open source projects. The current version of this bot only applies a very limited set of labels, however we are currently A/B testing new models that allow personalized labels. Here is a blog post discussing this project in more detail. . | Issue Triage GitHub Action: to compliment the Issue Label Bot, we created a GitHub Action that automatically adds / removes Issues to the Kubeflow project board tracking issues needing triage. . | Together these projects allow us to reduce the toil of triaging issues. The GitHub Action makes it much easier for the Kubeflow maintainers to track issues needing triage. With the label bot we have taken the first steps in using ML to replace human intervention. We plan on using features extracted by ML to automate more steps in the triage process to further reduce toil. . Building Solutions with GitHub Actions . One of the premises of Kubeflow is that a barrier to building data driven, ML powered solutions is getting models into production and integrated into a solution. In the case of building models to improve OSS project health, that often means integrating with GitHub where the project is hosted. . We are really excited by GitHub’s newly released feature GitHub Actions because we think it will make integrating ML with GitHub much easier. . For simple scripts, like the issue triage script, GitHub actions make it easy to automate executing the script in response to GitHub events without having to build and host a GitHub app. . To automate adding/removing issues needing triage to a Kanban board we wrote a simple python script that interfaces with GitHub’s GraphQL API to modify issues. . As we continue to iterate on ML Models to further reduce toil, GitHub Actions will make it easy to leverage Kubeflow to put our models into production faster. A number of prebuilt GitHub Actions make it easy to create Kubernetes resources in response to GitHub events. For example, we have created GitHub Actions to launch Argo Workflows. This means once we have a Kubernetes job or workflow to perform inference we can easily integrate the model with GitHub and have the full power of Kubeflow and Kubernetes (eg. GPUs). We expect this will allow us to iterate much faster compared to building and maintaining GitHub Apps. . Call To Action . We have a lot more work to do in order to achieve our goal of reducing the amount of toil involved in maintaining OSS projects. If your interested in helping out here’s a couple of issues to get started: . Help us create reports that pull and visualize key performance indicators (KPI). https://github.com/kubeflow/code-intelligence/issues/71 . We have defined our KPI here: issue #19 | . | Combine repo specific and non-repo specific label predictions: https://github.com/kubeflow/code-intelligence/issues/70 . | . In addition to the aforementioned issues we welcome contributions for these other issues in our repo. .",
            "url": "https://coding-shed.com/2020/01/01/Microsoft-Word-Example-Post.html",
            "relUrl": "/2020/01/01/Microsoft-Word-Example-Post.html",
            "date": " • Jan 1, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": ". My name is Michał Strzałkowski, I am data science and programming enthusiast. .",
          "url": "https://coding-shed.com/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://coding-shed.com/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}